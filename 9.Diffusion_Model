## Diffuion model

import os
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from diffusers import DDPMPipeline, DDPMScheduler
from diffusers.models import UNet2DModel
import pickle
import numpy as np
import os
import torch
from torch.utils.data import Dataset, DataLoader
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from diffusers import DDPMPipeline, DDPMScheduler
from diffusers.models import UNet2DModel
def unpickle(file):
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict


def load_cifar10(data_dir):
    # Load all training batches
    train_data = []
    train_labels = []
    for i in range(1, 6):
        batch = unpickle(os.path.join(data_dir, f'data_batch_{i}'))
        train_data.append(batch[b'data'])
        train_labels += batch[b'labels']
    
    train_data = np.concatenate(train_data)
    train_data = train_data.reshape(-1, 3, 32, 32).astype(np.float32)
    train_labels = np.array(train_labels)

    # Load test batch
    test_batch = unpickle(os.path.join(data_dir, 'test_batch'))
    test_data = test_batch[b'data'].reshape(-1, 3, 32, 32).astype(np.float32)
    test_labels = np.array(test_batch[b'labels'])

    return (train_data, train_labels), (test_data, test_labels)

# Path to CIFAR-10 data directory
data_dir = 'cifar-10-python/cifar-10-batches-py'  # Corrected path
(train_data, train_labels), (test_data, test_labels) = load_cifar10(data_dir)

class CIFAR10Dataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image = self.data[idx]
        label = self.labels[idx]
        image = image.transpose((1, 2, 0))  # Change from (C, H, W) to (H, W, C)
        if self.transform:
            image = self.transform(image)
        return image, label

# Example transformation
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize
])

# Create datasets
train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform)
test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform)

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)


# Define the UNet model
model = UNet2DModel(
    in_channels=3,  # 3 channels for RGB images
    out_channels=3,
    layers_per_block=2,
    block_out_channels=(64, 128, 256, 512),
    down_block_types=("DownBlock2D", "DownBlock2D", "DownBlock2D", "AttnDownBlock2D"),
    up_block_types=("AttnUpBlock2D", "UpBlock2D", "UpBlock2D", "UpBlock2D"),
)

# Define the scheduler
scheduler = DDPMScheduler(num_train_timesteps=1000)
def train_model():
    # Training loop
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

    for epoch in range(10):  # Number of epochs
        for i, (images, _) in enumerate(train_loader):
            images = images.to(device)  # Shape: (batch_size, 3, 32, 32)
            batch_size = images.shape[0]

            noise = torch.randn_like(images).to(device)  # Shape: (batch_size, 3, 32, 32)
            timesteps = torch.randint(0, scheduler.num_train_timesteps, (batch_size,), device=device).long()  # Shape: (batch_size,)

            # Forward pass
            noisy_images = scheduler.add_noise(images, noise, timesteps)  # Shape: (batch_size, 3, 32, 32)
            model_output = model(noisy_images, timesteps).sample  # Shape: (batch_size, 3, 32, 32)

            # Calculate loss
            loss = torch.nn.functional.mse_loss(model_output, noise)  # Loss between predicted noise and actual noise

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if i % 100 == 0:
                print(f"Epoch {epoch}, Step {i}, Loss: {loss.item()}")

    # Save the model
    model.save_pretrained("diffusion_model")
    scheduler.save_pretrained("diffusion_scheduler")

def load_model():
    global model, scheduler
    model = UNet2DModel.from_pretrained("diffusion_model")
    scheduler = DDPMScheduler.from_pretrained("diffusion_scheduler")

# User prompt
choice = input("Do you want to use the saved model or retrain? (use/retrain): ").strip().lower()

if choice == "retrain":
    train_model()
elif choice == "use":
    if os.path.exists("diffusion_model") and os.path.exists("diffusion_scheduler"):
        load_model()
    else:
        print("Saved model not found. Training the model.")
        train_model()
else:
    print("Invalid choice. Please type 'use' or 'retrain'.")

# Generate an image from noise
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# Sample a random noise image
num_inference_steps = 1000  # The number of denoising steps
image_size = (1, 3, 32, 32)  # Batch size 1, 3 color channels, 32x32 resolution
random_noise = torch.randn(image_size).to(device)

# Use the model to denoise the image
with torch.no_grad():
    generated_image = random_noise
    for t in reversed(range(num_inference_steps)):
        timesteps = torch.tensor([t] * image_size[0]).to(device)
        predicted_noise = model(generated_image, timesteps).sample
        generated_image = scheduler.step(predicted_noise, t, generated_image).prev_sample

# Post-process the generated image
generated_image = (generated_image * 0.5 + 0.5).clamp(0, 1)  # Scale to [0, 1] range
generated_image = generated_image.cpu().permute(0, 2, 3, 1).numpy()  # Convert to numpy array and move channels

# Save or display the generated image
image = Image.fromarray((generated_image[0] * 255).astype(np.uint8))
image.save("generated_image.png")
image.show()

