import tensorflow as tf

# Check TensorFlow version
print("TensorFlow version:", tf.__version__)

# Check if TensorFlow is built with CUDA
print("TensorFlow built with CUDA:", tf.test.is_built_with_cuda())

# Check GPU availability
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
print("List of available GPUs: ", tf.config.experimental.list_physical_devices('GPU'))

# List logical devices
print("List of logical devices: ", tf.config.experimental.list_logical_devices('GPU'))

print(tf.__version__)

import torch

# Check if CUDA (GPU support) is available
if torch.cuda.is_available():
    print("CUDA is available. You have the following GPU(s):")
    for i in range(torch.cuda.device_count()):
        print(f"  {i}: {torch.cuda.get_device_name(i)}")
else:
    print("CUDA is not available. PyTorch is using the CPU.")

# Enable device placement logging
tf.debugging.set_log_device_placement(True)

# Your TensorFlow code here
# Create some tensors
a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
b = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])

# Perform a matrix multiplication
c = tf.matmul(a, b, transpose_b=True)

print(c)


print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

import tensorflow as tf
print("TensorFlow version:", tf.__version__)
